---
title: "计算机科学速成课005"
description: Crash Course Computer Science
date: 2023-03-18T23:31:13+08:00
image: 
math: 
license: 
categories:
  - study
tags:
  - CS
hidden: false
comments: true
draft: false
---
# 计算机科学速成课

# Crash Course Computer Science

## 指令和程序 Instructions & Programs

> Last episode we combined an ALU, control unit, some memory, and a clock together to make a basic but functional central processing unit or CPU.我们已经用电路做了很多组件，这次我们给CPU一些指令来运行。

CPU之所以强大是因为它是可编程的==programmable==。如果写入不同指令，就会执行不同任务。 So the CPU is a piece of ==hardware==硬件 which is controlled by Easy-to-modify ==software==软件

那个，就RAM存8位，前四位opcode，后四位address或者寄存器的那个，然后我们就把，就比如00101110看成“LOAD_A 14”，就更容易理解。

提一下，add命令，那个顺序很重要，就两个寄存器嘛，add的结果会存在第二个寄存器里。

一些新的指令

<img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\PL\@I\PL@IOE28{XBMFOOHM$I]}BP_tmb.jpg" alt="img" style="zoom:50%;" />

Now we've got a ==subtract== function, which like ADD, specifies two registers to operate on.

---

### JUMP

We've also got a fancy new instruction called ==JUMP==. As the name implies, this causes the program to jump to a new location. This is useful if we want to change the order, or choose to skip some instructions. For example, a JUMP 0 would cause the program to go back to the beginning. At a low level(的从), this is done by writing the value specified in the last four bits into the instruction address register(指定地址寄存器), overwriting the current value. 

---

### JUMP_NEGATIVE

We've also added a special version of JUMP called ==JUMP_NEGATIVE==. This only jumps the program if the ALU's negative flag==负数标志== is set to true. The negative flag is only set when the result of an arithmetic operation is negative. 算数结果为负，负数标志才是真

<img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\{J\~P\{J~PM@)MLM8B5P]RK31QAE3_tmb.jpg" alt="img" style="zoom:50%;" />

If the result was zero or positive, the negative flag would not be set, so the JUMP_NEGATIVE wouldn't jump anywhere, and the CPU will just continue on to the next instruction.

---

### HALT

Computers need to be told when to stop processing, so we need a ==HALT== instruction. Our previous program really should have look like this to be correct, otherwise the CPU will just continued on after the STORE instruction processing all the 0s. But there is no instruction with an opcode 0, so the computer would have just crashed.

<img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\P2\}D\P2}DX0K(H)AKYW_U8AI0{$H_tmb.jpg" alt="img" style="zoom:50%;" />

It's important to point out here that we're storing both instructions on data in the same memory(指令和数据都是存在统一内存中) There is no difference fundamentally. -- it's all just binary numbers. So the HALT instruction is really important because it allows us to separate the two. 

---

### add JUMP - infinite loop

okay so let's make our program a bit more interesting by adding a JUMP. We also modify our two starting values in memory to 1 and 1. Let's step through this program just as our CPU would.

<img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\KU\~X\KU~XIROR3AI8A]RU))}NQHU_tmb.jpg" alt="img" style="zoom:50%;" />

First LOAD_A 14 loads the value 1 into Register A. Next LOAD_B 15 loads of value 1 into Register B. As before, we ADD registers B and A together, with the sum going into Register A. 1+1=2, so now Register A has the value 2 in it(stored in binary of course). Then the STORE instruction saves that into memory location 13.

Now we hit a "JUMP 2" instruction. This causes the processor to overwrite the value in the instruction address register(指令地址寄存器) which is currently 4,, with the new value 2.

<img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\0M\@R\0M@R}57HZE5]@BQGT`JQ$UV_tmb.jpg" alt="img" style="zoom:50%;" />

On the processer's next fetch cycle, we don't fetch HALT, instead we fetch the instruction at memory location 2, which is ADD B A. Register A contains the value 2, and Register B contains the value one. 1+2=3, so now Register A has the value 3. we store that into memory, and we've hit the JUMP again, back to ADD B A. 

Every loop we're adding 1. It's counting up, cool. But notice there's no way to ever escape. We never ever going to hit that HALT instruction. This is called an ==Infinite Loop==无限循环 - a program that runs forever. 

To break the loop, we need a conditional JUMP. A JUMP that only happens if a certain condition is met. Our JUMP_NEGATIVE is one example of a conditional JUMP, but computers have other types too, like JUMP IF EQUAL and JUMP IF GREATER. 

So let's make our code a little fancier and step through it.

---

### conditional JUMP

Like before, the program starts by loading values from memory to registers A and B. In this example, the number 11 gets loaded into Register A and 5 gets loaded into Register B. Now we subtract register B from register A. 11-5=6. 6 gets saved into Register A. 

Now we hit our JUMP NEGATIVE. The last ALU result was 6. That's a positive number, so the negative flag is false.

<img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\1A\S7\1AS7`B2ZBXRPQ9N3E@NH0ZM_tmb.jpg" alt="img" style="zoom:50%;" />

That means the processor does not jump. So we continue on the next instruction, which is JUMP 2. No conditional on this one, so we jump to  instruction 2 no matter what. Okay so we're back at our SUBTRACT Register B from Register A. 6-5=1. So 1 gets saved into Register A. 

Next instruction we're back again at our JUMP NEGATIVE. 1 is also a positive number. So the CPU continues onto the JUMP 2, looping back around again to the SUBTRACT instruction. This time is different though. 1-5=-4

So the ALU sets its negative flag to true the first time. 

<img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\UD\C5\UDC54CWPF6}`9`FT$M{_@01_tmb.jpg" alt="img" style="zoom:50%;" />

Now when we advance to the next instruction, JUMP NEGATIVE 5, the CPU executes the jump to memory location 5. 

We're out of the infinite loop.

We have an ADD B A. Negative 4 plus 5 is positive 1, and we save that into Register A. Next we have a STORE instruction that saves register a into memory address 13. Lastly we hit our HALT instruction and the computer rests.

So even though this program is only 7 instructions long, the CPU ended up executing 13 instructions, and that's because it looped twice internally.

---

This code calculated the remainder(余数) if we divide 5 into 11, which is one. With a few extra lines of code, we could also keep track of how many loops we did, the count of which would be how many times 5 went into 11... we did two loops, so that means 5 goes into 11 two times... with a remainder of 1.

And of course this code could work for any two numbers, which we can just change in memory to whatever we want. That's the power of software. Software also allowed us to do something how hardware could not. Remember our ALU didn't have the functionality to divide two numbers , instead it's the program we made that gave us that functionality. And then other programs can use our divide programs doing fancier things. 

And you know what that means. New levels of abstraction.

---

### 指令长度，可变指令长度，ending

> Our hypothetical CPU is very basic - all this instructions are 8 bits long, with the opcode occupying only the first four bits. So even if we used every combination of 4 bits, our CPU would only be able to support maximum 16 different instructions. On top of that, several of our instruction used the last 4 bits to specify a memory location. But again, 4 bits can only encode 16 different values, meaning we can address a maximum of 16 memory locations. That's not a lot to work with. 
>
> For this reason, real, modern CPUs use two strategies.
>
> The most straightforward approach is just have bigger instructions, with more bits, like 32 or 64 bits. This is called the ==instruction length 指令长度==. Unsurprisingly.
>
> The second approach is to use ==variable length instructions 可变指令长度==. For example, imagine a CPU that uses 8 opcodes. When the CPU sees an instruction that needs no extra values, like the HALT instruction, it can just execute it immediately. However if it sees something like a JUMP instruction, it knows it must also fetch the address to jump to, which is saved immediately behind the JUMP instruction in memory.  This is called, logically enough, an ==Immediate Value 立即值==.
>
> In such processor designs, instructions can be any number of bytes long, which makes the fetch cycle of the CPU a tad more complicated. 

Now, our example CPU and instruction set is hypothetical, designed to illustrate key working principles. So I want to leave you with a real CPU example.

> In 1971, Intel released the 4004r processor. It was the first CPU placed in a single chip and paved the path to the Intel processors we know in love today. It supported 46 instructions, shown here, which was enough to build an entire working computer.
>
> <img src="file:///C:\Users\dell\Documents\Tencent Files\371975940\Image\Group2\S5\CI\S5CIR7IDG13@K%0M8IY7]FA_tmb.jpg" alt="img" style="zoom:50%;" />
>
> And it used many of the instructions we've talked about, like JUMP ADD SUBTRACT and LOAD. It also uses 8-bit immediate values, like we just talked about, for things like JUMPs, in order to address more memory.
>
> And processors have come a long way since 1971. A modern computer processor like an Intel core i7, has thousands of different instructions and instruction variants, ranging from one to fifteen bytes long. And this huge growth in instruction set size is due in large part to extra bells of whistles that have been added to processor of designs overtime.

## 高级CPU设计 Advanced CPU Designs



> As we've discussed throughout the series, computers have come a long way from mechanical devices, capable of maybe one calculation per second, to CPUs running a kilohertz and megahertz speeds.
>
> In the early days of electronic computing, processors were typically made faster by improving the switching time of the transistors inside the chip - the ones that make up all the logic gates, ALUs, and other stuff we've talked about. But just making transistors faster and more efficient only went so far, so processor designers have developed various techniques to boost performance allowing not only simple instructions to run fast, but also performing much more sophisticated operations.

Last episode, we created a small program for our CPU that allowed us to divide two numbers.  We did this by doing many subtractions in a row . When we hit zero, or a negative number, we knew that we're done. But this approach gobbles up a lot of clock cycles, and isn't particularly efficient. So most computer processors today have divide as one of the instructions that the ALU can perform in hardware.

Of course, this extra circuitry makes the ALU bigger and more complicated to design, but also more capable - it's a ==complexity-for-speed tradeoff== that has been made many times in computing history. For instance, modern computer processors now have special circuits for things like graphic operations, decoding compressed video, and encrypting files, all of which are operations that would take many many many clock cycles to perform with standard operations.

You may even have heard of processors with MMX, 3DNOW, or SSE. These are processors with additional, fancy circuits that allow them to execute additional fancy instructions - for things like gaming and encryption. These extensions to the instruction set have grown, and grown over time , and once people have written programs to take advantage of them, it's hard to remove them. So instruction sets tend to keep getting larger and larger, keeping all the old opcodes around for ==backwards compatibility 向后兼容性==. 为了兼容旧指令集，指令数量越来越多。

The Intel 4004, the first truly integrated CPU, had 46 instructions, which was enough to bulid a fully functional computer. But a modern computer processor has thousands of different instructions, which uilizes all sorts of clever and complex internal circuitry. Now, high clock speeds and fancy instruction sets tend to leads to another problem - getting data in and out of the CPU quickly enough. In this case, the bottle neck is RAM. 

---

### 总线 缓存

RAM is typically a memory module that lies outside the CPU. This means that data has to be transmitted to and form RAM along sets of data wires, called a ==bus 总线==.

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318215418823.png" alt="image-20230318215418823" style="zoom: 67%;" />

This bus might only be a few centimeters long, and remember those electrical signals are traveling near the speed of light, but when you're operating at gigahertz speeds - that's billionths of second - even the small delay starts to become problematic. It also takes time for RAM itself to lookup the address, retrieve the data and configure itself for output.

So a "load from RAM" instruction might take dozens of clock cycles to complete, and during this time, the processor is just sitting there idly waiting for the data. 

---

One solution is to put a little piece of RAM right on the CPU -- called a ==cache 缓存==. There isn't a lot of space on a processor'chip, so most caches are just kilobytes or maybe megabytes in size, where RAM is usually gigabytes. Having a cache speeds things up in a clever way. When the CPU requests a memory location for RAM, the RAM can transmit not just one single value, but a whole block of data. This takes only a little bit more time, but it allows this data block to be saved into the cache.

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318220634335.png" alt="image-20230318220634335" style="zoom:67%;" />

This tends to be really useful because computer data is often arranged and processed sequentially.

举个例子，比如说算某餐厅日收入，就比如取RAM里地址是100的数据，而RAM并不是只给1个值，是直接给一批，把地址100到200的都给缓存

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318221244289.png" alt="image-20230318221244289" style="zoom:67%;" />

那么当processor处理下一个数据，处理101位置的，那缓存就：我有，我给你。这样就不用去RAM取数据。

Because the cache is so close to the processor, it can typically provide the data in a single clock cycle -- no waiting required.

This speeds things up tremendously over having to go back and forth to RAM every single time.

When data requested in RAM is already stored in the cache like this, it's called a ==cache hit 缓存命中==, and if the data requested isn't in the cache,  so you have to go to RAM, it's called a ==cache miss 缓存未命中==. 

*The cache can also be used like a scratch space(临时空间), storing intermediate values(中间值) when performing a longer, or more complicated calculation.*

#### 缓存脏位

继续例子，比如CPU算完了一天的销售额，想把结果存到地址150。就像之前一样，数据是暂时存到cache里的，而不是直接给RAM。这么存速度更快，而且如果要接着算什么的话，取值也会快。然后这样问题就是：缓存里的数据和RAM原本存储的不一致了。

这个不一致需要记录，之后进行同步。

For this purpose, the cache has a special flag(特殊标记) for each block of memory it stores, called the ==dirty bit 脏位==

Most often this synchronization happens when the cache is full, but a new block of memory is being requested by the processor. Before the cache raises the old block to free up space, it checks its dirty bit, and if it's dirty, the old block of data is written back to RAM before loading in the new block. 

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318223435104.png" alt="image-20230318223435104" style="zoom:67%;" />

### 指令流水线 并行

Another trick to boost CPU performance is called ==instruction pipelining 指令流水线==. 

就比如洗衣机30分烘干机30分，然后可以边洗衣服边烘干，就是==并行处理 parallelize==.

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318223827028.png" alt="image-20230318223827028" style="zoom:67%;" />

Processor designs can apply the same idea.

之前演示了CPU按序处理，取值解码执行，这样重复。这种设计，一条指令需要三个时钟周期

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318224126318.png" alt="image-20230318224126318" style="zoom:67%;" />

但每阶段用的是CPU不同部分，所以可以并行处理。

While one instruction is getting executed, the next instruction could be getting decoded, and the instruction beyond that fetched for memory. All of these separate processes can overlap so that all parts of the CPU are active at any given time.

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318224434318.png" alt="image-20230318224434318" style="zoom:67%;" />

In this design, an instruction is executed every single clock cycle, which triples the throughput(吞吐量).

#### 乱序执行 推测执行

但就像cache，这个也会有一些问题，首先就是指令之间的依赖关系。比如你读一个数据，而现在正在执行的指令会改这个数据，那读到的就是旧数据。

> To compensate for this, pipelined processors have to look ahead for data dependencies, and if necessary, stall their pipelines to avoid problems.

现在高端的CPU能dynamically reorder instructiosn with dependencies，就动态排序有关依赖关系的指令，以此最小化流水线的停工时间（stall），这个叫==乱序执行 out-of-order execution==

---

另外的问题就是==条件跳转 conditional jump instructions==，比如JUMP NEGATIVE。These instructions can change the execution flow of a program depending on the value. A simple pipelined processor will perform a long stall when it sees a JUMP instruction, waiting for the value to be finalized. Only once the JUMP outcome is known, does the processor start refilling its pipeline.(空等)

But, this can produce long delays, so high-end processors have some tricks to deal with this problem too.

把JUMP想成是岔路口，高端CPU会猜测是要去哪边，然后根据猜测提前把指令放进流水线。这个是==推测执行 speculative execution==.

---

当JUMP的结果出来了，如果CPU猜的是对的，那就不用等直接运行，因为已经先放了正确指令了。但如果错了，那就要==清空流水线 pipeline flush==.

为了尽可能减少清空流水线，CPU厂商开发了复杂的方法来猜测哪条分支更有可能，叫==cranch prediction 分支预测==。现代CPU的正确率超过90%

理想情况下，流水线一个时钟周期可以完成1个指令。然后出现了==超标量处理器 superscalar==，一个时钟周期可以完成多个指令。

### 多核处理器

即使有流水线设计，但在指令执行阶段，处理器里有些区域还是可能会空闲。

For example, while executing an instruction that fetches a value from memory, the ALU just going to be sitting there, not doing a thing. So why not fetch-and-decode several instructions at once, and whenever possible, execute instructions that require different parts of the CPU all at the same time. we can take this one step further and add duplicate circuitry.

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318231034165.png" alt="image-20230318231034165" style="zoom:67%;" />

目前说的方法，都是优化1个指令流的吞吐量。另一个提升性能的方法是，同时运行多个指令流。用==多核处理器 multi-core processors==，就是一个CPU芯片里，有多个独立的处理单元，很像是有多个独立CPU

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318231251721.png" alt="image-20230318231251721" style="zoom:67%;" />

双核处理器：dual core processors

四核处理器：quad core processors

<img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318231432664.png" alt="image-20230318231432664" style="zoom:67%;" />



Because they're tightly integrated, like cache, allowing the cores to work together on shared computations.

### 超级计算机

多核不够时，可以一个电脑安多个CPU。对高端服务器，2个或4个CPU很常见，有时如果需要更高性能，然后就造了，==超级计算机 supercomputer==

比如做模拟宇宙形成，那需要强大的计算力。给普通电脑加几个CPU是没用的，需要很多很多很多很多很多CPU

> 现在为止，世上最快的计算机在中国无锡，国家超算中心。
>
> 神威·太湖之光有40960个CPU，每个CPU有256个核心
>
> <img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318232202365.png" alt="image-20230318232202365" style="zoom:67%;" />
>
> 所以这个机器总计每秒可以进行9.3亿亿次==浮点数运算==，==floating point math operations per second, FLOPS==
>
> <img src="C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230318232416899.png" alt="image-20230318232416899" style="zoom:67%;" />

So long story short not only have computer processors gotten a lot faster over the years, but also a lot more sophisticated, employing all sorts of clever tricks to squeeze out more and more cpmputation per clock cycle. *Our job is to wield that incredible processing power to do cool and useful things. That's the essence of programming.*